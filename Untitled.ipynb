{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_single_close_quote = u'\\u2019' # unicode\n",
    "dm_double_close_quote = u'\\u201d'\n",
    "END_TOKENS = ['.', '!', '?', '...', \"'\", \"`\", '\"', dm_single_close_quote, dm_double_close_quote, \")\"] # acceptable ways to end a sentence\n",
    "\n",
    "def get_data(fnames):\n",
    "    content = \"\"\n",
    "    for fname in fnames:\n",
    "        with open(fname) as f:\n",
    "            for line in f:\n",
    "                line = line.strip().lower();\n",
    "                if line == \"\": continue # empty line\n",
    "                if line.startswith(\"ychzhou\"):\n",
    "                    yield line.replace(\"ychzhou\", \"\").strip(), content\n",
    "                    content = \"\"\n",
    "                else:\n",
    "                    if line[-1] not in END_TOKENS:\n",
    "                        line += ' .'\n",
    "                    content += ' ' + line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data([\"data/tokenized/bytecup.corpus.train.0.txt\"])\n",
    "contents = []\n",
    "titles = []\n",
    "for cnt, (title, content) in enumerate(data):\n",
    "    contents.append(content)\n",
    "    titles.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '14', '15']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text='3.14:15'\n",
    "re.split('[.:]', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by christpher glazeksuperstock  == 21 stories our readers loved in 2017 ==  this was the year that felt like 50 years \n",
      "oktoberfest in municha resistance band workout at over 4 == what to do after graduating college ==  gary vaynerchuk once told a 20 year old taylor about what to do after graduating college \n",
      " kara swisher  == full transcript : former groupon ceo andrew mason on recode decode ==  on this episode of recode decode \n",
      " renounce baptism and unction  == the albigensian crusade and the black mass ==  today we are going to talk about the albigensian crusade or the crusade of the church against the cathars \n",
      " mihaly cziksentmihaly suggests  == the surprising secret to changing the world ==  introductionthe more you want to impact the rest of the world \n",
      " novi sad and sarajevo  == five things i 've learned from short-term travelling ==  i began my short term -lrb- sometimes business related \n",
      " chess grandmasters  == influential books i read in the last 2 years ==  either i 've become way better at choosing which books to read \n",
      "farnoosh == how to spend less , save more , and clean up your -lrb- financial -rrb- act ==  you can feel it \n",
      " ussf vice president carlos cordeiro also is running  == face of us soccer since 2006 wants out ==  u\n",
      " my name is enrico pasquotti  == leaving google for friendz : how we did handle the miracle ==  when things get tough or simply flat \n",
      " aesa radar systemstheir problem area  == india : how to deliver free high quality engineering education . ==  germany \n"
     ]
    }
   ],
   "source": [
    "for cnt, (title, content) in enumerate(zip(titles, contents)):\n",
    "    if cnt > 10: break\n",
    "    ss = re.split('[.:,!?\";]', content)\n",
    "    sv = vectorizer.transform(ss)\n",
    "    y = sv.dot(vectorizer.idf_) / [(len(s.strip().split()) + 10) for s in ss]\n",
    "    print(ss[np.argmax(y)], '==', title, '==', ss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111123"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_['christpher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.196994798246125"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.idf_[111123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.144212353328214e-06"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.pow(math.e, -12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
